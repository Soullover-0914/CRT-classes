{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0EgVFNGN15eOMTLfplRfu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Soullover-0914/CRT-classes/blob/main/Untitled15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "VXaWoEYuABmp"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = pipeline(\"sentiment-analysis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIPSMCtnAEo3",
        "outputId": "e3c92cdb-fa47-4785-e578-5fb6eac8de15"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = input(\"Enter the text: \")\n",
        "print(a(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz60C_6lAPsO",
        "outputId": "f5a22263-964d-4721-dfb7-a11a31620b93"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text: There is loin in thebushes\n",
            "[{'label': 'NEGATIVE', 'score': 0.9524207711219788}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen = pipeline(\"text-generation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtfVSyvZBO1f",
        "outputId": "66716ed9-01d0-4078-a25b-79c5538317f3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = input(\"Enter the text: \")\n",
        "t = gen(text, max_length = 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcNFcqYnOzQv",
        "outputId": "e1bcf6e8-83b4-4ca0-d1f5-2d2e38c9e6ab"
      },
      "execution_count": 27,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the text: once upon a time there lived a ghost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t[0].get('generated_text'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OHWLk8-RC6m",
        "outputId": "aea95d1f-d447-4506-86c9-4c0864ee57f4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "once upon a time there lived a ghostly maiden and her only son. These things I saw in the heavens, in the garden—I had seen a great city in my youth, and I was in admiration of her.\n",
            "\n",
            "And now, when the great city became a great house it was by far the most beautiful of many that had appeared. It could be said that at any day the sky was in a full bloom without any visible light, and the sun as seen there shone. So the people went about with great curiosity. As they went to the house they put their hat into their hands and listened to the singing of the songs that were sung in it. And once a day one spoke to her or looked into her or told the words.\n",
            "\n",
            "And now it was time for them to build in the whole house in order to build up the world's great houses. Now it was a great city, in a great part of the city it was a magnificent house of high and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = pipeline('ner')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay-6dhmYQ1Z-",
        "outputId": "de9568f6-75c7-4ee9-b81e-99d42905e5f3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = input(\"Enter the text: \")\n",
        "result = n(text)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2n0VqD0rWiMQ",
        "outputId": "d0c29489-c98d-489a-a3d3-1a3cd27829d3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the text: i am swaroop i am working in guntur\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'I-PER',\n",
              "  'score': np.float32(0.7023456),\n",
              "  'index': 3,\n",
              "  'word': 's',\n",
              "  'start': 5,\n",
              "  'end': 6},\n",
              " {'entity': 'I-PER',\n",
              "  'score': np.float32(0.7662568),\n",
              "  'index': 5,\n",
              "  'word': '##oop',\n",
              "  'start': 9,\n",
              "  'end': 12},\n",
              " {'entity': 'I-LOC',\n",
              "  'score': np.float32(0.6084235),\n",
              "  'index': 11,\n",
              "  'word': '##tur',\n",
              "  'start': 32,\n",
              "  'end': 35}]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa = pipeline(\"question-answering\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V39OjJlDbmZB",
        "outputId": "066e4fd2-255a-41b5-ed6b-feacd541a250"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = \"'Bity bought some butter, but the butterwas bitter butter. So Bity bought some better butter, to make the bitter butter better.'\""
      ],
      "metadata": {
        "id": "mxPntlohbrxo"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"What does Bitty bought?\""
      ],
      "metadata": {
        "id": "l0EkxA4tcF-Z"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa(question = q, context = c)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PToNmIiccLpI",
        "outputId": "2ac55430-534b-49b5-a251-996c9f4e4320"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.34570664167404175, 'start': 13, 'end': 24, 'answer': 'some butter'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = \"\"\"In the 16th century, an age of great marine and terrestrial exploration, Ferdinand Magellan led the first expedition to sail around the world. As a young Portuguese noble, he served the king of Portugal, but he became involved in the quagmire of political intrigue at court and lost the king’s favor. After he was dismissed from service by the king of Portugal, he offered to serve the future Emperor Charles V of Spain.\n",
        "A papal decree of 1493 had assigned all land in the New World west of 50 degrees W longitude to Spain and all the land east of that line to Portugal. Magellan offered to prove that the East Indies fell under Spanish authority. On September 20, 1519, Magellan set sail from Spain with five ships. More than a year later, one of these ships was exploring the topography of South America in search of a water route across the continent. This ship sank, but the remaining four ships searched along the southern peninsula of South America. Finally they found the passage they sought near 50 degrees S latitude. Magellan named this passage the Strait of All Saints, but today it is known as the Strait of Magellan.\n",
        "One ship deserted while in this passage and returned to Spain, so fewer sailors were privileged to gaze at that first panorama of the Pacific Ocean. Those who remained crossed the meridian now known as the International Date Line in the early spring of 1521 after 98 days on the Pacific Ocean. During those long days at sea, many of Magellan’s men died of starvation and disease.\n",
        "Later, Magellan became involved in an insular conflict in the Philippines and was killed in a tribal battle. Only one ship and 17 sailors under the command of the Basque navigator Elcano survived to complete the westward journey to Spain and thus prove once and for all that the world is round, with no precipice at the edge.\"\"\""
      ],
      "metadata": {
        "id": "RoXlKKQRcTdB"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"The 16th century was an age of great ______ exploration.\""
      ],
      "metadata": {
        "id": "FV8cwb6fd-Np"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa(question = q, context = c)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALgX3lO0eLLJ",
        "outputId": "b357dc6a-2b25-43a5-8ba0-b65c984820d8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.22924160957336426, 'start': 31, 'end': 71, 'answer': 'great marine and terrestrial exploration'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = pipeline(\"summarization\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9-Lhml9gvJy",
        "outputId": "3ff82569-0f35-4706-ff82-1124307c6ae1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = \"\"\"the story begins in the dystopian city-state of Khansaar, where Raja Mannar rules with an iron fist. His son, Vardha, shares a close friendship with Deva, a member of the Shouryaanga tribe. However, Raja Mannar orders the annihilation of the Shouryaanga tribe, and Deva's mother, the leader of the tribe, is killed in the massacre. In a pivotal moment, Vardha intervenes to save Deva and his mother, ensuring their exile to safety. Deva, devastated by the loss, vows to return if Vardha ever needs him.\n",
        "\n",
        "Years later, in 2017, Vardha has become the prince of Khansaar and is embroiled in a power struggle. His step-sister, Radha Rama, proposes a ceasefire agreement to stop the civil war plaguing the city, but this leads to a political crisis with various factions and mercenaries trying to control the kingdom. Vardha calls upon Deva to return and help him navigate the turmoil. Deva, who has been living a secluded life in Assam, agrees to come back, but his return is met with hostility. Deva’s strong sense of justice quickly becomes evident when he intervenes to stop a local thug from molesting a young girl. This act leads to his imprisonment by the corrupt system, but Deva escapes, igniting a series of violent confrontations.\n",
        "\n",
        "As Deva unravels the truth about his identity, he discovers that he is the true heir to the throne of Khansaar, being the son of Dhaara, the Shouryaanga tribe's leader. This revelation shifts the power dynamics, and Vardha, realizing Deva's lineage and strength, recognizes him as his \"Salaar\"—a trusted ally and leader. The two join forces to confront the mercenaries and corrupt officials that have been manipulating the system for their own gain. In the final battle, Deva’s leadership and strength lead to the defeat of their enemies, and he is declared the rightful heir to the throne.\n",
        "\n",
        "As the city of Khansaar begins to rebuild, Deva takes his place alongside Vardha as the new rulers. Despite the victory, the kingdom remains in a fragile state, and the power struggle is far from over. The film ends with the promise of more conflicts to come, setting the stage for the next chapter in the saga,\"\"\"\n"
      ],
      "metadata": {
        "id": "KsinmWGRh1gi"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = s(t)\n",
        "result[0].get('summary_text')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "B60TzKPmiVPC",
        "outputId": "76b4a7f9-27c4-41ab-b2cb-5008002bf843"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The story begins in the dystopian city-state of Khansaar, where Raja Mannar rules with an iron fist . Vardha shares a close friendship with Deva, a member of the Shouryaanga tribe . The film ends with the promise of more conflicts to come, setting the stage for the next chapter in the saga .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u = pipeline(\"fill-mask\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5kad6Bgijl7",
        "outputId": "6cacea30-5066-45d7-8af0-9bf2682ae488"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilroberta-base and revision fb53ab8 (https://huggingface.co/distilbert/distilroberta-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = u('I am Pursuing <mask> in University')"
      ],
      "metadata": {
        "id": "OFHNrFtfivLb"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H4JTT23i6xz",
        "outputId": "388b1c63-48b7-4e5c-cea9-2bc93f112610"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.16405591368675232,\n",
              "  'token': 42232,\n",
              "  'token_str': ' Philosophy',\n",
              "  'sequence': 'I am Pursuing Philosophy in University'},\n",
              " {'score': 0.12141429632902145,\n",
              "  'token': 15221,\n",
              "  'token_str': ' PhD',\n",
              "  'sequence': 'I am Pursuing PhD in University'},\n",
              " {'score': 0.06716007739305496,\n",
              "  'token': 8755,\n",
              "  'token_str': ' Masters',\n",
              "  'sequence': 'I am Pursuing Masters in University'},\n",
              " {'score': 0.06682102382183075,\n",
              "  'token': 4662,\n",
              "  'token_str': ' Science',\n",
              "  'sequence': 'I am Pursuing Science in University'},\n",
              " {'score': 0.06278140842914581,\n",
              "  'token': 9307,\n",
              "  'token_str': ' Studies',\n",
              "  'sequence': 'I am Pursuing Studies in University'}]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    }
  ]
}